# 研究方法

### 基于隐式潜在特征学习的模型（无监督）

为了填充评分矩阵，本项目采用了传统的矩阵分解方法奇异值分解（Singular Value Decomposition, SVD）和基于相似度的方法，计算餐厅（或用户）之间的余弦相似度来预测评分。这些方法通过隐式地学习用户和餐厅的潜在特征，将这些特征用于预测**评分预测模型中用户对尚未评价过的物品（如餐厅）的预测评分**。这种学习过程是无监督的，不依赖于预先标记的输出数据，而是从数据的结构本身中发现模式和关联。

### 奇异值分解SVD

在本项目中，SVD被用于获取评分矩阵的低秩近似，这种近似通过最小化原始稀疏矩阵与其近似矩阵之间的重建误差来实现。具体而言，SVD分解评分矩阵$R$为三个矩阵的乘积：$R \approx U \Sigma V^T$，其中$U$和$V$分别是左右奇异向量矩阵，而$\Sigma$是奇异值构成的对角矩阵。

选择较大的奇异值可以捕获大部分信息，而忽略较小的奇异值可以实现数据的降噪和维度的减少。

### 基于余弦相似度的预测

余弦相似度用于衡量两个餐厅或用户在评分行为上的相似性。通过比较一个餐厅与其他餐厅的相似度，可以预测一个用户对未评价餐厅的评分。在此方法中，相似度计算基于餐厅间评分向量的余弦角度，计算公式为：
$$
\text{similarity} = \cos(\theta) = \frac{A \cdot B}{\|A\| \|B\|}
$$
其中$A$和$B$是两个餐厅的评分向量。基于相似餐厅的评分，并分析用户的历史行为和偏好以及餐厅偏好的属性，来预测该用户在未来对某个餐厅的评价或评分。

### 基于显式潜在特征学习的模型（监督）

交替最小二乘法（Alternating Least Squares, ALS）和随机梯度下降（Stochastic Gradient Descent, SGD）是两种显式学习用户和餐厅潜在特征的监督学习方法。这些方法不仅学习潜在特征，还可以调整模型以适应用户和物品的特定偏好和行为模式。

### 使用交替最小二乘法ALS进行潜在特征学习

在交替最小二乘法（ALS）方法中，系统将每个用户和餐厅表示为一个$k$-维的特征向量。这里的$k$维特征向量中的每一维代表了用户或餐厅的一个潜在属性，这些属性通过模型的学习过程得以识别和优化。例如，对于用户，这些潜在特征可能包括对某类食物的偏好或对服务质量的敏感度；对于餐厅，特征可能包括菜品的多样性、环境的舒适度等。

在ALS的设置中，每个数据实例由一个用户向量$\mathbf{u}_i$和一个餐厅向量$\mathbf{v}_j$组成，这些向量在初始阶段通常是随机初始化的。用户给餐厅的评分$r_{ij}$是目标变量，模型通过用户向量和餐厅向量的点积来预测这个评分：

$$
\hat{r}_{ij} = \mathbf{u}_i^\top \mathbf{v}_j
$$

这里的$\mathbf{u}_i^\top \mathbf{v}_j$是用户$i$的特征向量与餐厅$j$的特征向量的点积，它代表了两者特征的匹配度。为了学习这些特征向量，ALS使用了一个损失函数，这个函数是预测评分和实际评分之间差异的均方误差，同时加入了对特征向量的$L_2$正则化以防止过拟合：

$$
L(\mathbf{U}, \mathbf{V}) = \sum_{(i, j) \in \Omega} (r_{ij} - \mathbf{u}_i^\top \mathbf{v}_j)^2 + \lambda (\|\mathbf{u}_i\|^2 + \|\mathbf{v}_j\|^2)
$$

其中$\Omega$是所有已知用户-餐厅评分的集合，$\lambda$是正则化参数，用于控制模型复杂度，防止过拟合。ALS通过迭代地固定$\mathbf{u}_i$来更新$\mathbf{v}_j$，反之亦然，这种交替更新的策略可以高效地找到最优的潜在特征向量，从而填补评分矩阵中的缺失值，实现对未知评分的预测。

### 使用随机梯度下降SGD模型进行潜在特征学习

在随机梯度下降模型中，与交替最小二乘法类似，每个用户和餐厅的潜在特征向量都是模型学习的对象。然而，SGD模型的独特之处在于它还引入了**偏差项的学习**，这些偏差项为每个用户和每个餐厅分别设置，这些偏差项的存在是由于**某些用户可能普遍给出比平均水平更高或更低的评分，同样，某些餐厅也可能平均收到比其他餐厅更高或更低的评分**。通过为每个用户和餐厅学习一个独立的偏差项，可以使潜在特征的学习不受这些固有偏差的影响。在SGD模型中，用户$i$对餐厅$j$的预测评分是由四部分组成的：全局平均评分（即所有已知评分的平均值）、用户偏差$b_u$、餐厅偏差$b_i$，以及用户和餐厅潜在特征向量的点积。这可以数学化表达为：

$$
\hat{r}_{ui} = \mu + b_u + b_i + \mathbf{u}_i^T \mathbf{v}_j
$$
其中，$\mu$是全局平均评分，$b_u$和$b_i$分别是用户和餐厅的偏差项，$\mathbf{u}_i$和$\mathbf{v}_j$分别是用户$i$和餐厅$j$的潜在特征向量。这种模型设计使得SGD不仅能够调整每个用户和餐厅的特定影响，而且可以通过优化过程中逐渐调整偏差和潜在向量，以最小化预测评分和实际评分之间的误差。因此，随机梯度下降（SGD）模型被广泛应用于推荐系统中，用于学习复杂的用户行为和物品属性。

### 将其转换为回归/分类问题

使用随机森林回归器对用户和物品的潜在特征向量进行回归学习，以预测评分。这种方法考虑了潜在特征之间的非线性关系，试图捕捉用户偏好和物品属性之间更复杂的相互作用。目标是最小化预测评分和实际评分之间的均方误差，从而提高预测精度。

### 基于随机森林回归器的模型

随机森林通过构建多个决策树并输出其预测结果的平均值，用于学习用户和餐厅之间复杂的非线性关系。在这里，它被用来作为一种回归模型，预测用户对餐厅的评分，基于用户和餐厅的潜在特征向量。

### 评估指标

项目中使用均方误差MSE作为评估模型性能的主要指标。MSE测量的是预测评分与实际评分之间差异的平方的平均值，计算公式为

$$
\text{MSE} = \frac{1}{n} \sum_{i=1}^n (\hat{y}_i - y_i)^2
$$

其中$\hat{y}_i$是预测值，$y_i$是实际值。低MSE表示高预测精度，意味着模型能有效捕捉用户和物品的潜在特征。